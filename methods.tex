%!TEX root = thesis_cgo.tex
\chapter{Theory \& Methods}
\epigraph{Life can only be understood backwards; but it must be lived forwards.}{S{\o}ren Kierkegaard}

The main technique I will use to study the behaviour of IDPs/IDRs is the computational technique of Molecular Dynamics (MD) simulations ~\cite{haile1992molecular}. Protein dynamics are shaped by various types of physical interactions, acting on many conformational degrees of freedom, and on timescales spanning femtoseconds to milliseconds. This level of complexity makes it very challenging to predict the dynamics, or compute ensemble quantities of IDPs {\it ab initio} . MD is a brute-force approach which addresses this problem by iteratively solving the equations of motion for every interaction in a system of atoms in 3D space.  What results is a trajectory and a velocity for every atom in the system in time, which we can use to visualize the conformational sampling of our IDP of interest and compute thermodynamic quantities. While this can be a computationally demanding task, it is currently the most reliable way of studying protein conformational sampling \silico and has been succesfully applied to many biomolecular systems ~\cite{karplus2002molecular}. We will use this approach to study the conformational dynamics of two isoforms of the \gct: WT, and Y11D.

\section{Molecular Dynamics Simulations}

We represent our system as a set of $N$ atoms represented as  vectors $R = \{\vek{r_1}, \vek{r_2}, ... , \vek{r_N}\}$ in three dimensional space. We then use classical Newtonian mechanics to obtain the changes in position of the atoms as a function of time. For a peptide in solution, this system would consist of the atoms in the peptide, ions, water atoms, and the forces arising from interactions between them. 

\subsection{Computing atomic trajectories}

MD is centered on the principle that the potential energy arising from interacting particles is a function of their positions in space. Given a function describing the potentials arising from interactions between the different atoms, which we call a force field, we can iterate through every atom in the system and calculate resulting forces as a function of potential energy. The potential energy given by the force field can be written as $V(\vek{r_1}, \vek{r_2}, ..., \vek{r_N})$ and is a function of the positions of each atom. Using the classical definition of force as $\vek{F} = m\vek{a}$, we can combine the positions of each atom with the force field to compute the force acting on each atom as follows.  

\begin{equation}
\vek{F_i}  = -\frac{\partial V(\vek{r_1}, \vek{r_2}, ..., \vek{r_i}, ... \vek{r_N)}}{\partial \vek{r_i}} 
 \end{equation}

 Given that the force on an atom is the result of interactions with all other atoms in the system, we obtain the force on a particular atom as the sum of the force of the interactions with all other atoms $j$ in the system,  $\vek{F_i} = \sum_{j} \vek{F_{ij}}$ Given the total force on an atom, we can compute its trajectory in space by numerically integrating Newton's equations of motion. This process is repeated and trajectories are stored and updated for the desired number of steps in the simulation.
 
 \begin{equation}
 \frac{\partial^2 \vek{r_{i}}}{\partial t^2} = \frac{\vek{F_i}}{m_i}
\end{equation}

\subsection{Force Field}

The functions for potential energy of every type of interaction in the system are defined in what we call a force field. The energy between two interacting atoms can be broken down into two broad types of interactions: bonded and non-bonded interactions.

\begin{equation}
E_{total} = E_{bonded} + E_{non bonded}
\end{equation}

The bonded energy term can be written as the sum of energies arising from the bond itself  ($E_{bond}$) which is a function of the bond length, the potential arising from the angle formed by the bond ($E_{angle}$), as well as the torsional/dihedral angle ($E_{dihedral}$) arising from the rotation of three bonds about two intersecting planes.

Non-bonded interactions can have two contributing factors; electrostatic force, and van der Waals force. The electrostatic potential ($E_{electrostatic}$) arises from the interaction of the charges of particles, while the van der Waals potential  ($E_{van der Waals}$ arises from the attraction or repulsion between uncharged groups. Combining all of these terms, we can write the full description of forces in the system as:

\begin{equation}
E(\vek{r_i},, ... \vek{r_{N}}) = E_{bond} + E_{angle} + E_{dihedral} + E_{van der Waals} + E_{electrostatic} 
\end{equation}


The MD algorithm evaluates $E(r_{N})$ at every time step to obtain the force on each atom, and therefore the trajectory at each time step. Given this low-level description of the system, more complex phenomena such as the hydrophobic effect and hydrogen bonding which are known to be essential to protein dynamics do not need to be coded explicitly in the models. Instead, they arise naturally from the definition of the system.

Another key component to the force field is the definition of parameters for the different types of interactions and particles in the system. Key parameters include values for charge, mass, bond length, etc. and are obtained from experimental measurements. The force field must naturally also contain a set of definitions for the various types of atoms and functional groups it can model. Therefore, the choice of force field can have important consequences on the outcome of the simulations and must be chosen with care.

In this work, we will be using the Optimized Potentials for Liquid Simulations - All Atom (OPLS-AA) force field ~\cite{jorgensen1988opls} that can be represented as:


\begin{equation}
E_{bond} = \sum_{bonds} K_{r} (\vek{r} - \vek{r_{0}})^2	
\end{equation}

\begin{equation}
 E_{angle} = \sum_{angles} k_{\theta} (\theta - \theta_0) 
\end{equation}

\begin{multline}
E_{dihedrals} = \sum_\mathrm{dihedrals} \Big( \frac {V_1} {2} \big[ 1 + \cos (\phi-\phi_1) \big] 
                + \frac {V_2} {2} \big[ 1 - \cos (2\phi-\phi_2) \big] \\
                + \frac {V_3} {2} \big[ 1 + \cos (3\phi-\phi_3) \big] 
                + \frac {V_4} {2} \big[ 1 - \cos (4\phi-\phi_4) \big] \Big)
\end{multline}

Where $\phi$ is the dihedral angle and $V_{i}$ are the coeffiecients in the Fourier series. Non-bonded energies are computed as follows:

\begin{equation}
E_{nonbonded} = \sum_{i>j} f_{ij} \left(
                    \frac {A_{ij}}{r_{ij}^{12}} - \frac {C_{ij}}{r_{ij}^6}
                    + \frac {q_iq_j e^2}{4\pi\epsilon_0 r_{ij}} \right)
\end{equation}

Where $A$ and $C$ represent combining rules which allow us to obtain the interaction energy of dissimilar non-bonded atoms. OPLS uses standard combining rules where $A_ij = \sqrt{A_{ii}A_{jj}}$ and $C_{ij} = \sqrt{C_{ii}C_{jj}}$ ~\cite{good1970new}.

We believe the OPLS-AA force field to be the best fit for modeling charge-dependent motions of the \gct. Whereas other popular force fields such as CHARMM were parametrized on X-ray crystallographic experimental values of folded globular proteins, the OPLS force field was optimized with quantum chemical calculations of charged short peptides ~\cite{kukol2008molecular}. This approach is likely to more accurately model the dynamics of unfolded peptides where other force fields may tend to favour the formation of collapsed stable secondary structure motifs ~\cite{henriques2015molecular, tran2008role}. Furthermore, it has been reported that the small and localized treatment of charged groups in OPLS-AA is well suited for systems where local charge interactions drive global dynamics ~\cite{vitalis2009absinth}. We show that a simulation under OPLS-AA is able to accurately produce an extended conformation for the \lq molecular ruler \rq polyproline ~\cite{schuler2005polyproline} \figref{fig:pp}. We also control the appropriateness of the force field by comparing MD values to NMR measurements on the same system.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{pp}
\FigureCaption{Polyproline Simulation}{Simulation of 39-mer polyproline peptide known to be fully extended ~\cite{schuler2005polyproline} behaves as expected and accesses high radius of gyration conformations in a $1 \mu s$ simulation using the OPLS-AA force field.}
\label{fig:pp}
\end{figure}


\subsection{Preparing the system for a simulation}

The starting point of an MD simulation is a force field and a set of initial atomic coordinates for the system of interest. Before a simulation can be successfully run, there are several pre-processing steps that must be executed. 

Hydrogen bonding and the hydrophobic effect play very important roles in shaping the dynamics of polypeptides therefore, the model must include water molecules. We place the peptide atoms in a simulated box under periodic boundary conditions where water molecules are introduced to fill the remaining space. All subsequent force calculations in MD will consider solvent-solvent and solvent-peptide atomic interactions. We use an explicit water regime, meaning that all solvent atoms are modeled as discrete units in the system. While faster alternatives to this paradigm which represent the solvent with mean field behaviour, known as implicit solvent models are available, it is well documented that an explicit treatment currently provides results with the highest accuracy ~\cite{onufriev2008implicit, arnold1994evaluation, zhou2003free}. 

Once the peptide is solvated, any initial steric clashes between atoms must be allowed to relax. Typically this involves executing an energy minimization algorithm which searches for atomic coordinates that minimize the forces between atoms to move the system towards an energy minimum. No minimization algorithm guarantees convergence to a global minimum in finite time on a realistic system. However, convergence to a local minimum is often sufficient to eliminate significant clashes. In this work, we use the steepest descent energy minimization algorithm implemented in GROMACS ~\cite{hess2008gromacs}. 

At this point, we could begin an MD simulation and obtain trajectories in the NVE ensemble (constant number of particles, volume, and energy). However, we are often interested in comparing results from MD to experimental measurements such as those from NMR where the system is under constant temperature and pressure. It is therefore necessary to ensure that the forces in the system do not produce large fluctuations in the pressure and temperature of the ensemble. In order to keep the temperature constant and achieve an NVT sampling (constant number of particles, volume, and temperature) we use a thermostat. Since the temperature of a system is a function of the kinetic energy, a thermostat re-scales the velocities of the atoms in the system to achieve a given temperature. Likewise, for maintaining constant pressure, a barostat adjusts the size of the simulation box to counteract fluctuations in pressure and thus achieving an NPT ensemble (constant number of particles, pressure, and temperature). During the equilibration step, we first let the system adjust to the desired temperature by executing a short simulation in NVT. Then under NPT we allow the system to adjust to the desired pressure. Once both equilibration simulations are complete, the system is ready for a full simulation.

\section{Trajectory Analysis}

The MD simulation generates a set of coordinates for every atom in the system as a function of time, $\vek{r(t)}$. From these trajectories we can compute several quantities to study conformational changes in the peptide over time. 

\subsection{Root Mean Square Deviation}

We measure the square displacement between the coordinates of atom $i$ at time $t$ weighted by the mass of the atom $m_i$. We iterate this process for every atom in the peptide to obtain a measure of the degree of change between two conformations in time weighted by atomic masses in matrix $M$.

\begin{equation}
\text{RMSD}(t_1, t_2) = \bigg[ M^{-1} \sum_{i=1}^{N} m_{i} \lvert \lvert \vek{r_{i}}(t_{1}) - \vek{r_{i}}(t_{2}) \rvert \rvert^2 \bigg]^\frac{1}{2}
\end{equation}

\subsection{Radius of gyration}

The radius of gyration is a measure of a structure's compactness. To obtain the radius of gyration, we compute the mean squared distance from the position vector $\vek{r_i}$ to the molecule's centre of mass $r_{mean}$.

\begin{equation}
R_g(\vek{r}) = \sqrt{N^{-1} \sum_{k=1}^{N} (\vek{r_k} - \vek{r_{mean}})^2}
\end{equation}

\subsection{Diffusion coefficient and Hydrodynamic Radius}

Like radius of gyration, diffusion coefficient (\diffusion) and hydrodynamic radius ($R_h$) is a proxy for the compactness of a macromolecule. However, \diffusion and $R_h$ are quantities that describe the size of the molecule in the context of their solvent. Because biomolecules perform all of their function in solution, and are shaped by their interactions with the solvent, these quantities are often more informative than $R_g$ for our purposes.

The translational diffusion coefficeint of a macromolecule is defined as the rate at which its center of mass is able to diffuse through a solvent of a given viscosity under a certain hydrodynamic model. Conformations with high diffusion rates experience rapid displacement of their center of mass, while conformations with greater viscous force with the solvent experience reduced diffusion coefficients. 

The process of computing the translational diffusion coefficient for a particular conformation is done by the software package \texttt{hydroNMR} ~\cite{de2000hydronmr}. The method of calculating the diffusion coefficient will not be discussed here in detail as it is beyond the scope of this work. The main concept is that the software models each atom in the system, in our case a trajectory obtained by MD, as a spherical bead. The resulting chain of beads is packed into a hexagonal lattice and internal beads are removed to extract a topology of residues exposed to the solvent. From this topology, the software calculates the frictional force that a given conformation would exert on the solvent, this quantity is contained in the translational friction tensor $\Xi$. The following expression gives us the translational diffusion tensor $\vek{D_t}$.

\begin{equation}
\vek{D_{t}} = k_BT\Xi_{t}^{-1}
\end{equation}

Where $k_B$ is the Boltzmann constant (\SI{1.380e-23}{\square\metre\kilo\gram\per\square\second\per\kelvin}) and T is the temperature in Kelvin. The trace of the translational diffusoin tensor is invariant regardless of the molecule's orientation and is thus used to define the translational diffusion coefficient $D_t$.

\begin{equation}
D_t = \frac{1}{3}tr(\vek{D_t})
\end{equation}

Knowing \diffusion, we can use the Stokes-Einstein equation to obtain an expression for the effective hydrodynamic radius which measures the diffusion of spherical particles in solvent.

\begin{equation}
R_h = \frac{k_{B}T}{6\pi \eta D_{t}}
\label{eq:stokes}
\end{equation}

Where $R_h$ is the hydrodynamic radius and $\eta$ is the viscosity of the solvent.

\subsection{Covariance Analysis}

When analyzing MD trajectories, we are often interested in observing coordinated, or correlated motions. This is because global motions are likely to be involved in some functional mechanism. However, molecular trajectories typically feature complex motions along many axes and time scales which can often make it difficult to detect coordinated motions. Local rearrangements, vibrations, rotations, and random diffusion are examples of non-coordinated motions that likely do not contribute to a functional mechanism. The goal in MD trajectory covariance analysis is to obtain the axes of motion where atoms in the peptide of interest show a high degree of correlation which could be indicative of a global coordinated motion. 

Covariance analysis, or principal component analysis is a mathematical tool which isolates principal axes, or components of correlated motion by computing the covariance between atoms at every time point in the simulation. We compute the covariance for pairs $r_i$, $r+j$ of $N$ atoms  in $3$ dimensions resulting in a covariance matrix of size $3N$. $M$ is again a matrix of atomic weights.


\begin{equation}
C_{ij} = \bigg\langle M_{ii}^{\frac{1}{2}} (\vek{r_i}(t) - \langle \vek{r_i}(t) \rangle) M_{jj}^{\frac{1}{2}} (\vek{r_j}(t) - \langle \vek{r_j}(t) \rangle) \bigg\rangle
\end{equation}

The eigenvectors of the covariance matrix, $C$ define the set of orthogonal axes along which maximize variance. Note that $\langle \quad \rangle$ denotes a time average. Due to the constraints imposed by the backbone, only a limited number of eigenvectors are expected to contribute most to global movements.

\begin{equation}
R^{T}CR = diag(\lambda_1, \lambda_2, ... \lambda_{3N}) \text{\qquad where \quad} \lambda_1 \geq \lambda_2 \geq \lambda_{3N}
\end{equation}

Where R is the transformation matrix whose columns contain an eigenvector. Using this matrix to diagonalize C, we get a diagonalized C containing the set of eigenvalues $\lambda_i$ for every eigenvector in R along its main diagonal. The magnitude of the eigenvalue tells us the amount of variance captured by its corresponding eigenvector and can thus be used to guide our projection toward the major axes of motion.

If we wish to visualize motions along a particular axis and filter out motions along other axes, we can project the coordinates of each atom along a specific eigenvector. We can use following transformation to obtain the new set of coordinates $\vek{p}(t)$.

\begin{equation}
\vek{p}(t) = R^{T}M^{\frac{1}{2}}\vek{r}(t)
\end{equation}

The resulting trajectory lets us visualize motions along any component and is a useful tool for detecting coordinated structural changes. 

%Another useful application of the covariance matrix is for comparing the structural sampling of major modes in two different trajectories. Such comparisons can be used to assess the convergence of sampling, as well as for detecting major changes in conformational sampling. We define a quantity known as the subspace overlap which corresponds to the degree of similarity between two trajectories along their major components. This problem is equivalent to comparing two matrices of eigenvectors and the space that they span and so the subspace overlap is defined as follows:
%
%\begin{equation}
%\text{overlap}(\vek{v}, \vek{w}) \equiv \frac{1}{n} \sum_{i=1, j=1}^{n,n} (\vek{v} \times \vek{w}) ^ 2
%\end{equation}
%
%\begin{equation}
%d = \sqrt{tr((\sqrt{C_1} - \sqrt{C_2}))^2}
%\end{equation}
%
%\begin{equation}
%\text{normalized overlap} (C_1, C_2) = 1 - \frac{d}{\sqrt{tr(C_1) + tr(C_2)}}
%\end{equation}


